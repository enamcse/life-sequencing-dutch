epochs: 30
batch_size: 64
max_length: 512
hidden_size: 280
hidden_ff: 2210
hidden_act: swish
n_encoders: 5
n_heads: 10
n_local: 7
local_window_size: 38
norm_type: rezero
att_dropout: 0.1
fw_dropout: 0.1
dc_dropout: 0.1
emb_dropout: 0.1
parametrize_emb: true
norm_input_emb: false
norm_output_emb: true
weight_tying: wt
training_task: mlm
experiment_name: pretrain_dutch_0
experiment_version: 1
attention_type: performer
multihead_dc: false
num_random_features: 436
learning_rate: 0.0001
weight_decay: 0.01
beta1: 0.9
beta2: 0.999
cls_num_targs: 3
epsilon: 1.0e-06
stage: pre_training
implementation: v1
version: 1.0
vocab_size: 11654
HPARAMS_PATH: pop2vec/llm/src/new_code/regular_hparams_medium.txt
CHECKPOINT_DIR: models/2020_medium/
MLM_PATH: encoded.h5
NUM_VAL_ITEMS: 1000
VOCAB_PATH: vocab.csv
VAL_CHECK_INTERVAL: 0.5
steps_per_epoch: 336
